import Camera_Manager
from pathlib import Path
import cv2 as cv
import pi_debugging as debug
import numpy as np
import matplotlib.pyplot as plt

class matchEngine:
    """ Scale invariant feature transform manager"""
    def __init__(self, matcherType='SIFT') -> None:
        """ Can use SIFT or ORB matching, sift is more accurate but requires a lot
        more runtime ~5x increase. 
        """
        if matcherType=='SIFT':
            self.matcher = cv.SIFT_create()
            self.bf = cv.BFMatcher(cv.NORM_L2, crossCheck=True)
        elif matcherType=='ORB':
            self.matcher = cv.ORB_create()
            self.bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)
        else:
            raise("Invalid matrhcerType, currently support'SIFT' and 'ORB'.")
        
        # initialize descriptors and key points
        self.kpCurrent = None
        self.des = None
    

def siftMatching(cam, matcherType='SIFT'):
    # Initiate ORB detector
    
    if matcherType=='SIFT':
        matcher = cv.SIFT_create()
        bf = cv.BFMatcher(cv.NORM_L2, crossCheck=True)
    elif matcherType=='ORB':
        matcher = cv.ORB_create()
        bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)

    ret, img1 = cam.read()
    while ret:
        ret, img2 = cam.read()
        imgGray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)
        imgGray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)

        # # find the keypoints and descriptors with ORB
        # kp1, des1 = orb.detectAndCompute(imgGray1,None)
        # kp2, des2 = orb.detectAndCompute(imgGray2,None)

        kp1, des1 = matcher.detectAndCompute(imgGray1,None)
        kp2, des2 = matcher.detectAndCompute(imgGray2,None)

        # Match descriptors.
        matches = bf.match(des1,des2)
        # Sort them in the order of their distance.
        # matches = sorted(matches, key = lambda x:x.distance)
        valid = [x for x in matches if x.distance < 100]
        print("Number of matches: ", len(valid))
        # Draw first 10 matches.
        img3 = cv.drawMatches(
            img1,kp1,img2,kp2,valid[:100],
            None,
            flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS
        )
        img3 = cv.cvtColor(img3, cv.COLOR_BGR2RGB)

        distances = [x.distance for x in matches]
        h = np.histogram(distances)
        plt.hist(distances, )
        plt.show()
        plt.imshow(img3)
        plt.show()
        # TODO: #2 Write better function for selecting the number of features to keep

        img1 = img2.copy()

def findSquareContours(img, contours, minArea, maxArea, drawCorners):
    """
    Receives list of contours and filters out squares
    To be a square a contours must:
        - Have 4 lines approximating it
        - have an area between min and max
        - have an aspect ratio between 0.8 and 1.2
    """
    squares = []
    for cnt in contours:
        x1,y1 = cnt[0][0]
        approx = cv.approxPolyDP(cnt, 0.03*cv.arcLength(cnt, True), True)
        area = cv.contourArea(cnt)
        if approx.shape[0] == 4 and area > minArea and area < maxArea:
            x, y, w, h = cv.boundingRect(cnt)
            ratio = float(w)/h
            if ratio >= 0.8 and ratio <= 1.2:
                squares.append(cnt)
                if drawCorners:
                    img = cv.drawContours(img, [cnt], -1, (0,255,255), 3)

    return img, squares

def estimate_coef(x, y):
    """
    Calculate linear regresion coef
    """
    # number of observations/points
    n = np.size(x)
  
    # mean of x and y vector
    m_x = np.mean(x)
    m_y = np.mean(y)
  
    # calculating cross-deviation and deviation about x
    SS_xy = np.sum(y*x) - n*m_y*m_x
    SS_xx = np.sum(x*x) - n*m_x*m_x
  
    # calculating regression coefficients
    b_1 = SS_xy / SS_xx
    b_0 = m_y - b_1*m_x
  
    return (b_0, b_1)

def findBoardCentreSquares(img, printImgs):
    """
    Finds the centre of chessboard.
    1. applies adaptive threshold to find grayscale image
    2. dilates image to seperate different squares from each other
    3. finds square contours
    4. delete everything except square contours
    5. erode image to return squares to original size
    6. use findChessboardcorner function

    """
    patternSize = (7, 3)

    # convert image to a grayscale image
    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
    
    # threshhold it into a binary image
    # a large window size is used 71 to only change
    # threshold slowly
    img1 = cv.adaptiveThreshold(
        img, 
        255,
        cv.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv.THRESH_BINARY_INV,
        71,
        2
    )

    # dilate the image to grow the white areas
    # leaving small black squares in the centre of open squares
    kernSize = 3
    img2 = cv.dilate(img1, np.ones((kernSize, kernSize)))

    # find the points of contours aproximate contours
    contours, hierarchy = cv.findContours(img2, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)

    # check each contours and save squares
    img, squares = findSquareContours(img, contours, minArea=100, maxArea=6000, drawCorners=printImgs)

    # Create fully white image and fill poly with black.
    # this leaves only the black squares of the chessboard in the image
    img3 = np.ones((480, 640), dtype=np.uint8)*255
    cv.fillPoly(img3, squares, 0)

    #Dilate the area to return the squares to their original size
    img3 = cv.erode(img3, np.ones((kernSize, kernSize)))
    retVal, corners = cv.findChessboardCorners(img3, patternSize)
    
    # Debug lines to plot different image stages
    if printImgs:
        cv.drawChessboardCorners(img, patternSize, corners, retVal)
        debug.showImg([img, img1, img2, img3])

    return retVal, corners

def getRotationMatrix(corners):
    """
    Finds the rotation matrix using the interior corners of the chessboard.
    The rotation matrix rotates the image around the center of the board.
    To align the board with the horizontal axis.

    
    Find the transformation matrix to transform the image frame to the base
    co-ordinate frame.

    The transformation moves the centerpoint to the origin and flips the y axis.
    """
    # calculate the linear regression of each row to find the 
    # rotation of the board.
    rows = np.zeros(shape=(3, 7, 2))
    coef = np.zeros(shape=(3,2))
    for i in range(3):
        rows[i] = np.reshape(corners[7*i:7*i+7, :, :], (7, 2))
        coef[i] = estimate_coef(rows[i, :, 0], rows[i, :, 1])
    
    # the orgin is the centre corner point of the chessboard.
    # the rotation angle is in degrees and positive CCW.
    gradient = np.mean(coef[:, 1])
    angle= np.arctan2(gradient, 1)
    origin = corners[10, 0, :]

    # Find a rotation matrix to rotate the image around the origin.
    # it also flips the image along the vertical axis
    # b0 = (1-np.cos(angle))*origin[0]-np.sin(angle)*origin[1]-origin[0]
    # b1 = np.sin(angle)*origin[0]+(1-np.cos(angle))*origin[1]-origin[1]

    R = np.array([
        [np.cos(angle), np.sin(angle)],
        [np.sin(angle), -np.cos(angle)]
    ])

    # T = np.reshape(-(R@origin), (2,1))
    T = np.reshape(origin, (2,1))

    # affine tranformation for image transformation
    M = cv.getRotationMatrix2D(origin, angle*180/np.pi, 1)
    # move origin to zero
    M[:, 2] -= origin
    # flip y axis
    M[1, :] = M[1, :]*-1 

    return R, T, M

def drawImgInBaseCoords(img, rotationMatrix):
    (h, w) = img.shape[:2]
    imgOffset = np.array([[0, 0, w], [0, 0, h]])
    imgRot = cv.warpAffine(img, rotationMatrix+imgOffset, dsize=(w*2, h*2))

    # draw lines on axis of image
    cv.line(imgRot, [0, 640], [480*2, 640], (255,255,255), thickness=2)
    cv.line(imgRot, [480, 0], [480, 640*2], (255,255,255), thickness=2)

    return imgRot

def main():
    imgPath = Path("Chessboard_detection", "TestImages", "03_03_2023", "5")

    cam = Camera_Manager.FakeCamera((480, 640), str(imgPath.resolve()))

    _, img = cam.read()

    # Find center strip on starting position of chess board
    retVal, corners = findBoardCentreSquares(img, printImgs=False)

    # raise exception when board not found
    if not retVal:
        raise("Could not find the chessboard pattern within the starting position \
              chess Board. Check that the board is visible.")

    # Find rotation matrix to align image with axes. 
    # assume centerpoint is origin
    R, T, rotationMatrix = getRotationMatrix(corners)

    imgRot = drawImgInBaseCoords(img, rotationMatrix)

    corners1 = np.reshape(corners, (21, 2))

    cornersTransformed = (R @ (corners1.T - T)).T

    for corner in cornersTransformed:
        pos=np.rint(corner).astype(int)+np.array([480, 640])
        cv.drawMarker(imgRot,(pos[0], pos[1]), color=(255, 255, 255), markerSize=5,thickness=2)
        # cv.drawMarker()
    # debug.showImg([imgRot])

    (h, w) = imgRot.shape[:2]
    plt.imshow(imgRot, origin='lower', extent=([-w/2, w/2, -h/2, h/2]))
    plt.show()

    siftMatching(cam)


if __name__ == "__main__":
    main()